{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a3e933b-f4ab-4e33-b022-5164a2d797c7",
   "metadata": {},
   "source": [
    "# Learning\n",
    "\n",
    "- [intro pandas](#Intro-to-pandas)\n",
    "- [univariate data](#Describing-univariate-data) : measures of tendency, spread\n",
    "- [bivariate data](#Bivariate-data) : feature scaling, scatterplot\n",
    "  - [feature scaling](#Feature-Scaling)\n",
    "- [linear modeling](#Modeling)\n",
    "  - [linear regression](#Linear-regression) : linear regression\n",
    "  - [train-test validation](#Train,-test,-validation): train test split\n",
    "  - [k-fold validation](#K-fold-validation): kfold validation\n",
    "  - [regularization](#Regularization): Ridge regression, lasso regression\n",
    "    - [ridge regression](#Ridge-Regresssion)\n",
    "    - [lasso regression](#Lasso-Regresssion)\n",
    "- [PCA](#PCA-and-dimensionality-reduction)\n",
    "- [Classification](#Classification)\n",
    "  - [K nearest neighbors](#K-nearest-neighbors)\n",
    "  - [Logistic Regression](#Logistic-Regression)\n",
    "  - [Decision trees](#Decision-Tree)\n",
    "  - [Random Forest](#Random-forests)\n",
    "  - [Concepts](#Concepts) : Grid search, Leave one-out validation, hard classifications vs soft classifications for decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57f866e2-a726-4add-bfe4-b2106a86a2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92c92b5-79d4-4a83-a10d-141fac27f104",
   "metadata": {},
   "source": [
    "## Intro to pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1261744-fe64-459e-99ac-28c2ed616027",
   "metadata": {},
   "source": [
    "### Locating elements with pandas\n",
    "\n",
    "When you have a pandas series, you have two methods for accessing data: `series.iloc` and `series.loc`\n",
    "\n",
    "- `series.iloc[n]` : gets the nth row of data of the series\n",
    "- `series.loc[index]` : gets all entries that have the specified index in the series.\n",
    "\n",
    "`series.iloc` will only ever return one entry, while `series.loc` can return multiple entries if there are duplicate indices in the series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f9043b-a084-4895-83ca-f9773ad4fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series([\"Ford\", \"Vasiliu\", \"Willner\", \"Vasiliu\"], index=[\"DATA201\",\"DATA301\",\"DATA201\",\"DATA201\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "385654d4-901a-47f9-b08c-7a876f1dda89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATA201       Ford\n",
       "DATA301    Vasiliu\n",
       "DATA201    Willner\n",
       "DATA201    Vasiliu\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1876784d-9a8c-4814-b753-1dee638f1727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ford'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a98332-26bb-427f-a5a4-a1f1dad0f0fa",
   "metadata": {},
   "source": [
    "In this specific example, we get back all entries that have a named index of \"DATA201\". Multiple elements have that index, so multiple entries are returned as a sub-series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceeb1190-fd1e-41a5-96de-c99aea7849cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATA201       Ford\n",
       "DATA201    Willner\n",
       "DATA201    Vasiliu\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.loc[\"DATA201\"] # multiple elements returned since duplicate series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def93573-ca6c-48e8-856b-11a4fca2d1bf",
   "metadata": {},
   "source": [
    "### Reading in data and looking at it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f0ffe4-4543-4be9-a765-c6c94c937e58",
   "metadata": {},
   "source": [
    "**`pd.read_csv()`**\n",
    "\n",
    "In this example, the `pd.read_csv(filepath)` method takes in a filepath to a csv and returns a dataframe. To specify the separator if it's different, use the `sep` keyword. \n",
    "\n",
    "It then returns a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c50ac5d9-1d87-49f5-abc7-0b6fc95c2a14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Continent</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Tourism_expenditure</th>\n",
       "      <th>Arrivals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Dem. Rep. of the Congo</td>\n",
       "      <td>1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Dem. Rep. of the Congo</td>\n",
       "      <td>2005</td>\n",
       "      <td>3.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Dem. Rep. of the Congo</td>\n",
       "      <td>2010</td>\n",
       "      <td>11.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Dem. Rep. of the Congo</td>\n",
       "      <td>2017</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Dem. Rep. of the Congo</td>\n",
       "      <td>2018</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Dem. Rep. of the Congo</td>\n",
       "      <td>2019</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>1995</td>\n",
       "      <td>3691.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>2005</td>\n",
       "      <td>5293.0</td>\n",
       "      <td>9178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>2010</td>\n",
       "      <td>5704.0</td>\n",
       "      <td>8744.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>2017</td>\n",
       "      <td>8508.0</td>\n",
       "      <td>12426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>2018</td>\n",
       "      <td>9097.0</td>\n",
       "      <td>12749.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>2019</td>\n",
       "      <td>8847.0</td>\n",
       "      <td>13285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Djibouti</td>\n",
       "      <td>1995</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Djibouti</td>\n",
       "      <td>2005</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Djibouti</td>\n",
       "      <td>2010</td>\n",
       "      <td>18.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Djibouti</td>\n",
       "      <td>2017</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Djibouti</td>\n",
       "      <td>2018</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Continent                 Country  Year  Tourism_expenditure  Arrivals\n",
       "0     Africa  Dem. Rep. of the Congo  1995                  NaN      35.0\n",
       "1     Africa  Dem. Rep. of the Congo  2005                  3.0      61.0\n",
       "2     Africa  Dem. Rep. of the Congo  2010                 11.0      81.0\n",
       "3     Africa  Dem. Rep. of the Congo  2017                  6.0       NaN\n",
       "4     Africa  Dem. Rep. of the Congo  2018                 61.0       NaN\n",
       "5     Africa  Dem. Rep. of the Congo  2019                100.0       NaN\n",
       "6     Europe                 Denmark  1995               3691.0       NaN\n",
       "7     Europe                 Denmark  2005               5293.0    9178.0\n",
       "8     Europe                 Denmark  2010               5704.0    8744.0\n",
       "9     Europe                 Denmark  2017               8508.0   12426.0\n",
       "10    Europe                 Denmark  2018               9097.0   12749.0\n",
       "11    Europe                 Denmark  2019               8847.0   13285.0\n",
       "12    Africa                Djibouti  1995                  5.0      21.0\n",
       "13    Africa                Djibouti  2005                  7.0      30.0\n",
       "14    Africa                Djibouti  2010                 18.0      51.0\n",
       "15    Africa                Djibouti  2017                 36.0       NaN\n",
       "16    Africa                Djibouti  2018                 57.0       NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/test_data_v2.csv\", sep=\",\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebea7d3-a94b-4e45-a675-19ee22537c14",
   "metadata": {},
   "source": [
    "**data describing methods**\n",
    "\n",
    "- `df.head()` : return first 5 entries as dataframe\n",
    "- `df.tail()` : return last 5 entries as dataframe\n",
    "- `df.describe()` : return numerical aggregation data on all numerical columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "369139ba-9849-416d-b765-db72bc9499ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Continent</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Tourism_expenditure</th>\n",
       "      <th>Arrivals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Dem. Rep. of the Congo</td>\n",
       "      <td>1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Dem. Rep. of the Congo</td>\n",
       "      <td>2005</td>\n",
       "      <td>3.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Dem. Rep. of the Congo</td>\n",
       "      <td>2010</td>\n",
       "      <td>11.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Dem. Rep. of the Congo</td>\n",
       "      <td>2017</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Dem. Rep. of the Congo</td>\n",
       "      <td>2018</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Continent                 Country  Year  Tourism_expenditure  Arrivals\n",
       "0    Africa  Dem. Rep. of the Congo  1995                  NaN      35.0\n",
       "1    Africa  Dem. Rep. of the Congo  2005                  3.0      61.0\n",
       "2    Africa  Dem. Rep. of the Congo  2010                 11.0      81.0\n",
       "3    Africa  Dem. Rep. of the Congo  2017                  6.0       NaN\n",
       "4    Africa  Dem. Rep. of the Congo  2018                 61.0       NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "714a142e-8083-4ade-9e14-1fce7c3fbdf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Continent</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Tourism_expenditure</th>\n",
       "      <th>Arrivals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Djibouti</td>\n",
       "      <td>1995</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Djibouti</td>\n",
       "      <td>2005</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Djibouti</td>\n",
       "      <td>2010</td>\n",
       "      <td>18.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Djibouti</td>\n",
       "      <td>2017</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Djibouti</td>\n",
       "      <td>2018</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Continent   Country  Year  Tourism_expenditure  Arrivals\n",
       "12    Africa  Djibouti  1995                  5.0      21.0\n",
       "13    Africa  Djibouti  2005                  7.0      30.0\n",
       "14    Africa  Djibouti  2010                 18.0      51.0\n",
       "15    Africa  Djibouti  2017                 36.0       NaN\n",
       "16    Africa  Djibouti  2018                 57.0       NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc239bf4-b455-4166-b0c5-01b050862c01",
   "metadata": {},
   "source": [
    "### Dataframe properties\n",
    "\n",
    "- `df.shape` : returns rows x columns tuple of dataframe\n",
    "- `df.dtypes` : returns a series of the columns and explains their data types\n",
    "- `df.columns` : returns a index of the column names in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "638ad109-5efd-465f-89f9-3900dcac65d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Continent               object\n",
       "Country                 object\n",
       "Year                     int64\n",
       "Tourism_expenditure    float64\n",
       "Arrivals               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a4dcd6c-2132-4f5f-84b9-75354c054475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Continent', 'Country', 'Year', 'Tourism_expenditure', 'Arrivals'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1ddfcc-5b84-4553-b29e-b41a04f47a45",
   "metadata": {},
   "source": [
    "### Dataframe indexing\n",
    "\n",
    "Using bracket notation we can access individual or multiple columns. \n",
    "\n",
    "Accessing a column by its column name returns a series, while accessing a list of column names returns a data frame. \n",
    "\n",
    "- `df[column_name]` : returns a series of the specified column. Returns `Series`\n",
    "- `df[[col1, col2, col3]]` : returns a dataframe including all the different columns. Returns `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ad62d99-92da-45e2-ab8c-3542d04b538c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Africa\n",
       "1     Africa\n",
       "2     Africa\n",
       "3     Africa\n",
       "4     Africa\n",
       "5     Africa\n",
       "6     Europe\n",
       "7     Europe\n",
       "8     Europe\n",
       "9     Europe\n",
       "10    Europe\n",
       "11    Europe\n",
       "12    Africa\n",
       "13    Africa\n",
       "14    Africa\n",
       "15    Africa\n",
       "16    Africa\n",
       "Name: Continent, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns series\n",
    "df['Continent'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01d5b90b-2352-4da8-891e-6dca6530eaff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Continent</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Dem. Rep. of the Congo</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Dem. Rep. of the Congo</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Dem. Rep. of the Congo</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Dem. Rep. of the Congo</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Dem. Rep. of the Congo</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Dem. Rep. of the Congo</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Djibouti</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Djibouti</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Djibouti</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Djibouti</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Djibouti</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Continent                 Country  Year\n",
       "0     Africa  Dem. Rep. of the Congo  1995\n",
       "1     Africa  Dem. Rep. of the Congo  2005\n",
       "2     Africa  Dem. Rep. of the Congo  2010\n",
       "3     Africa  Dem. Rep. of the Congo  2017\n",
       "4     Africa  Dem. Rep. of the Congo  2018\n",
       "5     Africa  Dem. Rep. of the Congo  2019\n",
       "6     Europe                 Denmark  1995\n",
       "7     Europe                 Denmark  2005\n",
       "8     Europe                 Denmark  2010\n",
       "9     Europe                 Denmark  2017\n",
       "10    Europe                 Denmark  2018\n",
       "11    Europe                 Denmark  2019\n",
       "12    Africa                Djibouti  1995\n",
       "13    Africa                Djibouti  2005\n",
       "14    Africa                Djibouti  2010\n",
       "15    Africa                Djibouti  2017\n",
       "16    Africa                Djibouti  2018"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Continent', 'Country', 'Year']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9637147f-4b25-416b-969b-f9dc61be4d1d",
   "metadata": {},
   "source": [
    "### Dealing with Missing data\n",
    "\n",
    "- `df.isnull()` : returns a boolena dataframe where the element is `True` if null, `False` if not null\n",
    "- `df.dropna(subset=col_list)` : drops all missing data in the columns specified in the `col_list`, which is a list of the column names to drop from. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa739fa-d928-4a08-b160-b9d2d1ebb92e",
   "metadata": {},
   "source": [
    "### Series Aggregation methods\n",
    "\n",
    "- `series.mean()` : returns the mean of the series\n",
    "- `series.max()` : returns the max of the series\n",
    "- `series.min()` : returns the min of the series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7cd628-7c59-4f73-a6d6-e6cce202d3a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Series conditionals\n",
    "\n",
    "To find all values in a series that equal \"turtle\", we can write code like this: \n",
    "\n",
    "```python\n",
    "series == \"turtle\"\n",
    "```\n",
    "\n",
    "All boolean expressions with conditionals will return a **boolean series** where every value in the series is a boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9b684ca-c226-422f-a564-ffe07914d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series([\"turtle\", \"potato\", \"turtle\", \"potato\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddf09fc1-fa74-4f22-abc2-34808b745b33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1    False\n",
       "2     True\n",
       "3    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series == \"turtle\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75adc67d-8e31-4697-a7f8-c47c1d516195",
   "metadata": {},
   "source": [
    "### Numpy array basics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767ebd9f-b287-4c8e-b8b4-2240ebbeec7d",
   "metadata": {},
   "source": [
    "#### Numpy array properties\n",
    "\n",
    "Here are some important properties on a numpy array:\n",
    "\n",
    "- `arr.dtype` : returns the data type of the array\n",
    "- `arr.ndim` : returns the number of dimensions of the array. Returns `int`\n",
    "- `arr.shape` : returns a tuple representing the size of each dimension in the array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff35e46-fe17-46e4-b737-483d32f28d13",
   "metadata": {},
   "source": [
    "#### Creating numpy arrays\n",
    "\n",
    "For all these array creation methods, they return a numpy array, and for the parameter they take in, it can be either a single number or a tuple. \n",
    "\n",
    "- If single number: means the resulting array will be one-dimensional, and the number you pass in specifies the size of the array\n",
    "- If tuple of numbers: represents the dimensional shape\n",
    "\n",
    "So here are all the useful array creation methods:\n",
    "\n",
    "- `np.zeros()` : creates array where every element is 0\n",
    "- `np.ones()` : creates array where every element is 1\n",
    "- `np.empty()` : creates array where every element is empty\n",
    "- `np.arange(start, stop, step)` : creates an array where elements are drawn from this incrementing range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44df098a-527a-4070-9d02-27989bb30828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1.]\n",
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "# LEVEL 1: 1D data\n",
    "\n",
    "print(np.zeros(5))\n",
    "print(np.ones(5))\n",
    "print(np.empty(5))\n",
    "print(np.arange(1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "848fc54a-56d7-4add-9a2e-43dc0df8df99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LEVEL 2: Multiple dimensions\n",
    "\n",
    "# to create an array with multiple dimensions, pass in a shape tuple into these methods\n",
    "\n",
    "np.zeros((5 , 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4e01b6-038b-43f4-942c-2ab9c8705ced",
   "metadata": {},
   "source": [
    "#### Numpy data types casting\n",
    "\n",
    "**METHOD 1: add dtype property**\n",
    "\n",
    "To cast an array as soon as you create it, pass the `dtype=` keyword arg into the `np.array()` method. Here is the basic syntax:\n",
    "\n",
    "```python\n",
    "np.array(arr, dtype=data_type)\n",
    "```\n",
    "\n",
    "**METHOD 2: use asstype()**\n",
    "\n",
    "The `arr.astype(data_type)` method returns the array casted to the specified data type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f3f5fe2-0976-4bf7-a34b-4ea16778cb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# starts out as int array\n",
    "\n",
    "arr = np.array([1, 2, 3, 4])\n",
    "arr.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35fe1b9f-5d39-4cdc-bfe7-43a4a0e8e063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cast to float array\n",
    "\n",
    "new_arr = arr.astype(float)\n",
    "new_arr.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a387913-db42-4cc1-a0cc-93e0c8da32e9",
   "metadata": {},
   "source": [
    "#### Reshaping data\n",
    "\n",
    "FOr reshaping data, all the methods below return a new modified array that has a different shape than the original, but it doesn't modify the original. \n",
    "\n",
    "- `arr.reshape(shape_tuple)` : takes in a tuple representing the sizes for each dimension and reshapes the array accordingly\n",
    "- `arr.ravel()` : flattens the array to 1 dimension\n",
    "- `arr.flatten()` : flattens the array to 1 dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2a8d5c-8df1-45ca-9703-a7f183e2aed7",
   "metadata": {},
   "source": [
    "#### Numpy aggregation methods\n",
    "\n",
    "Using numpy aggregation methods lives on the `np` object from numpy itself. There are different ways to change the aggregation behavior of these methods, depending on the `axis` property. \n",
    "\n",
    "- **default** : aggregates over all of the elements, returning a single value\n",
    "- **`axis=0`** : creates final aggregate value for each column. Returns an array, whose length is the number of columns. Aggregates down the rows to create a total for each column.\n",
    "- **`axis=1`** : creates final aggregate value for each row. Returns an array, whose length is the number of rows. Aggregates left to right on the columns to create a total for each row.\n",
    "\n",
    "And here are all the aggregation methods: \n",
    "\n",
    "- `np.sum(arr)` : gets the sum\n",
    "- `np.mean(arr)` : gets the mean\n",
    "- `np.min(arr)` : gets the min\n",
    "- `np.max(arr)` : gets the max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a298ba8-a713-47a9-9136-2822e4c78f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.71428571,  1.42857143,  2.14285714,  2.85714286],\n",
       "       [ 3.57142857,  4.28571429,  5.        ,  5.71428571,  6.42857143],\n",
       "       [ 7.14285714,  7.85714286,  8.57142857,  9.28571429, 10.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.linspace(0, 10, 15).reshape((3,5))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53345cea-b3d4-4294-ad7d-7c4cdcde463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(arr))  # sums all elements\n",
    "print(np.mean(arr, axis=0)) # mean of each column (summing down by rows)\n",
    "print(np.mean(arr, axis=1)) # mean of each row (summing right by columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a1fcca4-c447-46b0-9637-b62e50939e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1464"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(71)\n",
    "np.sum(np.random.randint(10, 21, (1, 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7fda10-a49f-42db-92c4-867c8eaf6a07",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Describing univariate data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ff68a4-dbb1-4e56-be09-324b964203c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Intro to stats\n",
    "\n",
    "- **nominal data** : categorical data with no order to the data\n",
    "- **ordinal data** : categorical data with order to the data and labels\n",
    "- **continuous data** : numerical data that includes decimals\n",
    "- **discrete data** : numerical data that includes only integers or a finite collection of integers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ac9f7f-b54f-4c77-a2f9-ca328338d9b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Measures of central tendency\n",
    "\n",
    "Based on the skewness of the distribution, these facts are guaranteed:\n",
    "\n",
    "- **Symmetric** : mean = median\n",
    "- **Right skewed** : mean > median\n",
    "- **Left Skewed** : mean < median\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "When data is skewed, the best measure of central tendency is the median and the best measure of spread is the IQR.\n",
    "</div>\n",
    "\n",
    "Here are the methods to get measures of central tendency: \n",
    "\n",
    "- `np.mean(arr)` : gets the mean of the data\n",
    "- `np.median(arr)` : gets the median of the data\n",
    "\n",
    "**Best measures of central tendency for each situation**\n",
    "\n",
    "- **Median** : when dealing with ordinal data or with skewed data\n",
    "- **Mean** : When dealing with evenly distributed data like in a normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943165e4-8a4f-4edd-82d9-959969bdebec",
   "metadata": {},
   "source": [
    "### Measures of spread\n",
    "\n",
    "- **variance** : we can use the `np.var(arr)` method to get the variance of the data within a vector.\n",
    "- **standard deviation** : we can use the `np.std(arr)` method to get the standard deviation of the data within a vector.\n",
    "- **coefficient of variation** : the coefficient of variation is the standard deviation divided by the mean, $\\frac{\\sigma}{\\mu}$.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    If you try to calculate the coefficient of variation on standard scaled data, then you will get an error because standard scaled data always has a mean = 0 and variance = 1, thus 1 / 0 nets you undefined.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84f4feb8-6d1c-4ea6-9943-2c3c850c666d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard deviation: 1.0902109621927198\n",
      "variance: 1.1885599420851762\n",
      "coefficient of variation 3.4092197684483057\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(20)\n",
    "\n",
    "print(\"standard deviation:\", np.std(x))\n",
    "print(\"variance:\", np.var(x))\n",
    "print(\"coefficient of variation\", np.std(x) / np.mean(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dedb3b4-bf68-47ea-90ef-fbcd55a6e0bc",
   "metadata": {},
   "source": [
    "### Getting better resolution\n",
    "\n",
    "We use **log transformation** to get better resolution on a plot where our data varies widely between magnitudes, like on a range from 1,000 - 350,000.\n",
    "\n",
    "- `np.log10(arr)` : applies base 10 log to all elements in the array. Returns new array\n",
    "- `np.log(arr)` : applies natural log to all elements in the array. Returns new array\n",
    "\n",
    "We want to apply the log 10 transformation on our features that vary widely in magnitude. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3001ae40-565c-4d07-97bb-9c81bf0bb432",
   "metadata": {},
   "source": [
    "### Box plots\n",
    "\n",
    "Box plots help us see measures of spread and central tendency. It's unique shape tells us a lot about the data: \n",
    "\n",
    "- **bottom of box** : Q1, 25th percentile of data\n",
    "- **middle line** : Q2, the median, at 50th percentile of data\n",
    "- **top of box** : Q3, at 75th percentile of data\n",
    "- **bottom whisker** : $\\mathrm{Q1} - 1.5\\mathrm{IQR}$\n",
    "- **top whisker** : $\\mathrm{Q3} + 1.5\\mathrm{IQR}$ \n",
    "\n",
    "We consider a data point to be an outlier if it lies beyond the bounds of the bottom and top whiskers, or in other words, if it is greater than than $1.5(IQR)$ outside the bounds of the min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b061c80-a689-4c38-be2f-305f7d47caf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 18, 16,  9, 19, 14,  3,  5, 11,  4, 60])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([*np.random.randint(3, 20, 10), 60])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67843972-3f8c-4c7d-a184-4aed12811e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "plt.boxplot(arr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360949df-800c-49db-ad11-a945e8cb123d",
   "metadata": {},
   "source": [
    "## Bivariate data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b8e5de-d3ec-4ade-9d36-ce90b4c31147",
   "metadata": {},
   "source": [
    "### Correlation coefficient\n",
    "\n",
    "Use the `np.corrcoef(x,y)` method to return a matrix of the two fields and how they correlate with each other. \n",
    "\n",
    "You can then create a scatterplot of the data with `plt.scatter(x, y)` to fact check the correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e593a061-53c3-4c18-9b7c-f528fbe34185",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_correlation_heatmap(dataframe: pd.DataFrame):\n",
    "    # 1. clean up dataframe to have numerical data only and drop null rows\n",
    "    numerical_df = dataframe[dataframe.select_dtypes(include='number', exclude='object').columns]\n",
    "    numerical_df = numerical_df.dropna()\n",
    "    cols = list(numerical_df.columns)\n",
    "\n",
    "    #2. run correlation coefficient matrix\n",
    "    corr_matrix = np.corrcoef(numerical_df[cols], rowvar=False)\n",
    "    mask = np.triu(corr_matrix)\n",
    "\n",
    "    #3. plot heatmap\n",
    "    sns.heatmap(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1,\n",
    "                annot=True, fmt='.2f', xticklabels=cols[:-1], yticklabels=['']+cols[1:],\n",
    "            mask = mask)\n",
    "    plt.tick_params(size = 0, labelsize = 12)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77eab6f-fe09-4ecc-9e75-7631eec89cb9",
   "metadata": {},
   "source": [
    "#### Creating a correlation heatmap\n",
    "\n",
    "With the method below, we can clean up a dataframe data, make a correlation matrix from it, and then plot it's heatmap easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f38f4f20-907f-4c29-a3b8-e84d83da5587",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_correlation_heatmap\u001b[39m(dataframe: \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[1;32m      2\u001b[0m     numerical_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m     corr_matrix \u001b[38;5;241m=\u001b[39m dataframe\u001b[38;5;241m.\u001b[39mcorr()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "def create_correlation_heatmap(dataframe: pd.DataFrame):\n",
    "    # 1. include only numerical columns\n",
    "    numerical_df = dataframe[dataframe.select_dtypes(include='number', exclude='object').columns]\n",
    "\n",
    "    # 2. drop na\n",
    "    numerical_df = numerical_df.dropna()\n",
    "    cols = list(numerical_df.columns)\n",
    "\n",
    "    # 3. create correlation matrix\n",
    "    corr_matrix = np.corrcoef(numerical_df[cols], rowvar=False)\n",
    "    mask = np.triu(corr_matrix)\n",
    "\n",
    "    # 4. plot\n",
    "    sns.heatmap(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1,\n",
    "                annot=True, fmt='.2f', xticklabels=cols[:-1], yticklabels=['']+cols[1:],\n",
    "            mask = mask)\n",
    "    plt.tick_params(size = 0, labelsize = 12)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3809b8cd-f2a5-4b9d-bbe5-425f1ccbce7e",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "We want to ensure that all features in a dataset have a similar range, on the level of $-1 \\le x \\le 1$. \n",
    "\n",
    "To do this, we divide each value of a feature by the range of the feature, like so: $\\frac{x}{s}$\n",
    "\n",
    "**Motivation**\n",
    "\n",
    "Why do we want to do feature scaling? Imagine you have a set of three students: \n",
    "\n",
    "- Student A: 1400 SAT, 4.0 GPA\n",
    "- Student B: 1400 SAT, 2.0 GPA\n",
    "- Student C: 1460 SAT, 4.0 GPA\n",
    "\n",
    "We would say that Student A and C are more similar, since they have the same GPA, and similar SAT scores, but that's not what happens here. \n",
    "\n",
    "The change is weighted more towards SAT because it lies on a range of 0-1600, while the GPA is on a range of 0-4.\n",
    "\n",
    "**Standard scaling**\n",
    "\n",
    "Standard scaling fits features to a normal distribution, making each feature have a mean $\\mu=0$ and a standard deviation $\\sigma=1$\n",
    "\n",
    "The formula for standard scaling is this: \n",
    "\n",
    "$$\\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "You subtract the mean from each feature value, and then divide that by the standard deviation.\n",
    "\n",
    "This is the exact same thing as the Z-score. It returns the z-score of each feature value, about how many standard deviations the observation is from the mean.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    Each feature scaled with standard scaling will always have a mean = 0 and standard deviation = 1.\n",
    "</div>\n",
    "\n",
    "**Min/max scaling**\n",
    "\n",
    "Min max scaling follows this formula:\n",
    "\n",
    "$$\\frac{x - min}{range}$$\n",
    "\n",
    "What's important about this is that all scaled values will be within the range 0-1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed78d747-5d5e-4fa2-80f9-7d4c6052ec4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.1666666666666667, 1.0),\n",
       " (1.1666666666666667, 0.5),\n",
       " (1.2166666666666666, 1.0)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_a = (1400, 4)\n",
    "student_b = (1400, 2)\n",
    "student_c = (1460, 4)\n",
    "\n",
    "students = [student_a, student_b, student_c]\n",
    "\n",
    "# 1. GET ranges\n",
    "SAT_RANGE = 1600 - 400\n",
    "GPA_RANGE = 4 - 0\n",
    "\n",
    "# 2. Scale by range\n",
    "scaled_students = [(x[0]/SAT_RANGE, x[1]/GPA_RANGE) for x in students]\n",
    "scaled_students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce84ff29-abd2-40aa-817d-2f8cf0e48ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 0.05, 0.502]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def norm(x1, y1, x2, y2):\n",
    "    return round(math.sqrt((x2 - x1)**2 + (y2-y1)**2), 3)\n",
    "\n",
    "distances = [\n",
    "    norm(*scaled_students[0], *scaled_students[1]), # student A vs student B\n",
    "    norm(*scaled_students[0], *scaled_students[2]), # student A vs student C\n",
    "    norm(*scaled_students[1], *scaled_students[2])  # student B vs student C\n",
    "]\n",
    "\n",
    "# from the distances, we can see student A is closest to student C\n",
    "distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c72f643-7501-4f56-b9ff-62df94f0734a",
   "metadata": {},
   "source": [
    "Now let's do an example with standard scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e78ab40-fdd4-43ab-8d60-8f9c2ac60bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_scores = np.array([1400, 1460, 1400, 1200])\n",
    "gpa = np.array([3.5, 2.5, 4.0, 3.8])\n",
    "\n",
    "def feature_scale(arr):\n",
    "    return (arr - np.mean(arr))/np.std(arr)\n",
    "\n",
    "feature_scaled_sat = feature_scale(sat_scores)\n",
    "feature_scaled_gpa = feature_scale(gpa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98e543a9-0664-41f1-ac95-31a92bc2f6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.35583     0.96582428  0.35583    -1.67748427]\n",
      "[ 0.086711   -1.64750894  0.95382097  0.60697698]\n"
     ]
    }
   ],
   "source": [
    "print(feature_scaled_sat)\n",
    "print(feature_scaled_gpa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37468389-aa03-4e9b-9e6c-9d7152281664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "plt.scatter(feature_scaled_sat, feature_scaled_gpa)\n",
    "plt.xlabel(\"SAT\")\n",
    "plt.ylabel(\"GPA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f456df0-9208-4d0d-98e9-0d9900132f3a",
   "metadata": {},
   "source": [
    "#### Feature scaling with standard scaler\n",
    "\n",
    "We can get access to a standard scaler through the sklearn library, like so: \n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "standard_scaler = SS()\n",
    "```\n",
    "\n",
    "- `ss.fit_transform(df)` : takes in a dataframe or another 2D array, and then feature scales all the feature columns. It returns the scaled dataframe or array.\n",
    "- `ss.fit(df)` : calculates mean and standard deviation of data and stores it in the `ss` object. Returns `None`\n",
    "- `ss.transfom(df)` : feature scales the data after you call `ss.fit()`. Only does this for standard scaler, but applies fitted parameters to data\n",
    "\n",
    "These three methods do different things depending on which object instance of sklearn you use. Here is how they work in general: \n",
    "\n",
    "- `.fit()` : fits the data to the model\n",
    "- `.transform()` : transforms the model\n",
    "- `.fit_transform()` : fits the data to the model, and then returns the transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6082b498-bdf9-479a-a56e-11ccf190d495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "733f8e3a-c7fe-4c40-b02e-e9ed0327a41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT score</th>\n",
       "      <th>GPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1460.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1400.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1200.0</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SAT score  GPA\n",
       "0     1400.0  3.5\n",
       "1     1460.0  2.5\n",
       "2     1400.0  4.0\n",
       "3     1200.0  3.8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_scores = np.array([1400, 1460, 1400, 1200])\n",
    "gpa = np.array([3.5, 2.5, 4.0, 3.8])\n",
    "\n",
    "data = np.vstack([sat_scores, gpa]).T\n",
    "students = pd.DataFrame(data=data, columns=[\"SAT score\", \"GPA\"])\n",
    "students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9aa5161-ec2d-42c4-a98e-a72270dc8bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03ed7d81-ac5e-4dfe-ab37-cb5a2598cfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df = standard_scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6d45587-eee2-449e-b668-267fdce43734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35583   ,  0.086711  ],\n",
       "       [ 0.96582428, -1.64750894],\n",
       "       [ 0.35583   ,  0.95382097],\n",
       "       [-1.67748427,  0.60697698]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d72df27-5c60-4cca-955a-552f7fc1b6c9",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e49d5e-a062-490e-ae89-ec0202d9667d",
   "metadata": {},
   "source": [
    "### Linear regression\n",
    "\n",
    "For linear regression, the hypothesis will be a linear equation with any amount of features. This can be univariate or multivariate linear regression: \n",
    "\n",
    "$$h_\\beta (x) = \\beta_0 + \\beta_1 x $$\n",
    "$$ h_\\beta (x) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... $$\n",
    "\n",
    "The goal in linear regression is to minimize the squared error consisting of all the data points: \n",
    "\n",
    "$$C = \\sum (\\hat{y} - y)^2$$\n",
    "\n",
    "**SKLearn linear regression**\n",
    "\n",
    "1. Import the `LinearRegression` class and instantiate it\n",
    "\n",
    "    ```python\n",
    "    from sklearn.linear_model import LinearRegression as LR\n",
    "    lr = LR()\n",
    "    ```\n",
    "    \n",
    "2. Fit the model to the data using `lr.fit()`\n",
    "\n",
    "    ```python\n",
    "    lr.fit(x, y)\n",
    "    ```\n",
    "    \n",
    "3. Get the predicted data $\\hat y$ back with `lr.predict()`\n",
    "\n",
    "   ```python\n",
    "   y_hat = lr.predict(x)\n",
    "   ```\n",
    "\n",
    "Here are the methods and properties available on the linear regression instance: \n",
    "\n",
    "- `lr.coef_` : the 2D matrix of coefficients for the features (parameters)\n",
    "- `lr.intercept_` : the 1D array of intercepts\n",
    "- `lr.score(x, y)` : returns an $R^2$ score for the data, showing how well the model's features fit the target.\n",
    "- `lr.fit(x, y)` : fits data to linear regression model\n",
    "- `lr.predict(x)` : returns the array of predictions that the model makes\n",
    "\n",
    "**Coefficient of determination**\n",
    "\n",
    "THe coefficient of determination is $R^2$, and has bounds $(-\\infty, 1]$. \n",
    "\n",
    "*ONLY* in two dimensions, then you have a correlation coefficient $r$ which is just the square root of the coefficient of determination. \n",
    "\n",
    "$$r = \\sqrt{R^2}$$\n",
    "\n",
    "The null model is just predicting the mean, which means that the null model has an $R^2$ value = 0\n",
    "\n",
    "\n",
    "**Mean squared error**\n",
    "\n",
    "MSE is a better error metric for models created based on the exact same data.\n",
    "\n",
    "You can only compare model performance with MSE if the models are based on the same data.\n",
    "\n",
    "This is how we'll use scikit learn to do meane squared error: \n",
    "\n",
    "1. Import the `mean_squared_error()` method from scikit learn\n",
    "\n",
    "   ```python\n",
    "   from sklearn.metrics import mean_squared_error\n",
    "   ```\n",
    "\n",
    "2. The method takes in two arguments: the model's prediction and the expected values. Both should be numpy arrays\n",
    "\n",
    "    ```python\n",
    "    mean_squared_error(y_hat, y)\n",
    "    ```\n",
    "**Euclidian squared distance**\n",
    "\n",
    "THe euclidean squared distance is just the distance formula squared. Essentially we do it because we don't need to square root everything, making ti less computationally expensive to compute. \n",
    "\n",
    "**Coefficient of variation**\n",
    "\n",
    "THe coefficient of variation is another way to tell how spread out our data is. It's just the standard deviation divided by mean, and then we multiply by 100 to get a percentage. \n",
    "\n",
    "It's useful because it works no matter whether your data is scaled or unscaled. \n",
    "\n",
    "$$CV = \\frac{\\mathrm{standard \\ deviation}}{\\mathrm{mean}} \\cdot 100$$\n",
    "\n",
    "- A low CV means the data points tends to be close to the mean\n",
    "- A high CV means the data points tend to be farther away from the mean, spread out over a wide range.\n",
    "\n",
    "**Null model**\n",
    "\n",
    "The null model will just predict that every point is equal to the mean, giving a straight line. Then from there, we can get the coefficient R^2, which is the coefficient of determination.\n",
    "\n",
    "$$R^2 = 1 - \\frac{\\mathrm{Sum \\ of \\  actual \\ squared \\  errors}}{\\mathrm{Sum\\  of\\  squared\\  errors\\  using \\ \\ null\\  model}}$$\n",
    "\n",
    "You can also think of it like this: \n",
    "\n",
    "$$R^2 = 1 - \\frac{\\sum (\\hat y - y)^2}{\\sum (\\hat y - \\mu)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62bbf963-bb98-4026-81eb-ae5857b6c9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. import the linear regression object\n",
    "from sklearn.linear_model import LinearRegression as LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59cf69ec-7517-40bd-99f2-8f4f52d54ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. create data\n",
    "np.random.seed(146)\n",
    "x = np.random.normal(size=(10,1))\n",
    "noise_strength = 0.5\n",
    "noise = np.random.normal(scale=noise_strength, size=(10,1))\n",
    "y = 1 + 2*x + noise\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.scatter(x,y, label='Original data', color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ffc8373-62ac-400d-984b-20294e8fa4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3: run linear regression\n",
    "\n",
    "lr = LR()\n",
    "lr.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02b741f7-e76f-40ef-a567-ae398cb11cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.77218448],\n",
       "       [ 1.18729095],\n",
       "       [-0.7249848 ],\n",
       "       [-0.40065615],\n",
       "       [ 2.5548401 ],\n",
       "       [ 0.72398075],\n",
       "       [-1.61163342],\n",
       "       [ 2.57138316],\n",
       "       [ 1.19973579],\n",
       "       [ 1.64945564]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4: get predictions from hypothesis\n",
    "\n",
    "y_hat = lr.predict(x)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7ba48d8-b1db-42ac-b76d-b9af76e36843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. plot line\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.scatter(x,y, label='Original data', color='k')\n",
    "plt.plot(x, y_hat, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb14b04-f5a5-481c-afae-17e3761fd0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. create model\n",
    "\n",
    "def predict(x):\n",
    "    model = np.dot(lr.coef_, x) + lr.intercept_\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a7d2cf-6be0-4083-883d-405dcdbedf0c",
   "metadata": {},
   "source": [
    "#### Scaling in OLS\n",
    "\n",
    "For regression with OLS, scaling is not required. When scaling, you only scale the features. You never scale the target because doing so would require you to undo the scaling later.\n",
    "\n",
    "> There's a reason why we call it feature scaling. We only scale the features.\n",
    "\n",
    "The parameters and intercepts will change to account for any changes when you scale the data, but you will end up with the same model. \n",
    "\n",
    "i>}\r\n",
    "</style>\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1007f5ce-cd29-4e3c-a50a-2609495dfb7e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">It does not matter whether or not you do feature scaling for regression since you will end up with the same result.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fc38d1-111d-4089-8ea3-614b37fa74da",
   "metadata": {},
   "source": [
    "#### Standard Scaling\n",
    "\n",
    "Here are the rules for standard-scaling data with linear regression: \n",
    "\n",
    "- Only scale the features, not the target\n",
    "- Only scale the test data based on the specs (mean and standard deviation) from the training data.\n",
    "- Any time you are predicting data, any input data must also be scaled using the mean and standard deviation calculated from the model.\n",
    "\n",
    "<div class=\"alert alert-info\">Always scale the test features with the same scalar spes as the training data</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f973bbd8-dbd9-4824-a4da-429063f55651",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_Xtrain = np.array([[56,5], [53,3], [94,4], [78,8],[15,5], [34,4], [53,5], [44,4]])\n",
    "ex_Ytrain = np.array([51, 51, 95, 82, 16, 29, 55, 49])\n",
    "ex_Xtest = np.array([[98, 6], [53,4]])\n",
    "ex_Ytest = np.array([81,38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15e12655-283f-47bf-a18f-4f75d1710618",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ex_Xtrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m ss \u001b[38;5;241m=\u001b[39m SS()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 2. fit standard scaler to training data features\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m ss\u001b[38;5;241m.\u001b[39mfit(\u001b[43mex_Xtrain\u001b[49m)\n\u001b[1;32m      9\u001b[0m scaled_Xtrain \u001b[38;5;241m=\u001b[39m ss\u001b[38;5;241m.\u001b[39mtransform(ex_Xtrain)\n\u001b[1;32m     10\u001b[0m scaled_Xtest \u001b[38;5;241m=\u001b[39m ss\u001b[38;5;241m.\u001b[39mtransform(ex_Xtest)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ex_Xtrain' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "\n",
    "# 1. create standard scaler\n",
    "ss = SS()\n",
    "\n",
    "# 2. fit standard scaler to training data features\n",
    "ss.fit(ex_Xtrain)\n",
    "\n",
    "# 3. scaled both training and testing data with scaler (based on training specs)\n",
    "scaled_Xtrain = ss.transform(ex_Xtrain)\n",
    "scaled_Xtest = ss.transform(ex_Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3f2d03-0ed1-4915-b122-0b619685a1c2",
   "metadata": {},
   "source": [
    "### Train, test, validation\n",
    "\n",
    "**overfitting and underfitting**\n",
    "\n",
    "When we overfit a data set, essentially the model just well on the training data but fails to generalize on the testing data. It means training score is less than testing score.\n",
    "\n",
    "When we underfit a data set, it performs poorly on both the training set and and test set.\n",
    "\n",
    "- **internal validity** : how well the model performs on the training data\n",
    "- **external validity** : how well the model performs on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15136760-cae4-4541-b8dc-1a0c44a2a4a6",
   "metadata": {},
   "source": [
    "#### Train test-split\n",
    "\n",
    "The `tts()` method takes in an array of features and an array of target data, and then returns an array of 4 nested arrays, representing the training data and testing data respectively.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(x, y, test_size=0.2, shuffle=True, random_state=201)\n",
    "```\n",
    "\n",
    "The first two arguments you pass to the `tts()` method are the array of features, `x`, and the array of target values `y`. Then after that here are the kwargs you can supply: \n",
    "\n",
    "- `test_size=` : the percentage of data to allocate to testing. 20% is pretty good here.\n",
    "- `shuffle=` : whether to randomly sort data or not.\n",
    "- `random_state=` : `int`. a random seed to set so that you get back the same split every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d3ca987-8bf2-4b9e-91cb-422957913f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/test_data_v2.csv\", sep=\",\")\n",
    "df.dropna(subset=['Tourism_expenditure', 'Arrivals'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77f4ff57-9848-4ee6-8040-ccf0af7f401d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Continent</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Tourism_expenditure</th>\n",
       "      <th>Arrivals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Dem. Rep. of the Congo</td>\n",
       "      <td>2005</td>\n",
       "      <td>3.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Dem. Rep. of the Congo</td>\n",
       "      <td>2010</td>\n",
       "      <td>11.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>2005</td>\n",
       "      <td>5293.0</td>\n",
       "      <td>9178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>2010</td>\n",
       "      <td>5704.0</td>\n",
       "      <td>8744.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>2017</td>\n",
       "      <td>8508.0</td>\n",
       "      <td>12426.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Continent                 Country  Year  Tourism_expenditure  Arrivals\n",
       "1    Africa  Dem. Rep. of the Congo  2005                  3.0      61.0\n",
       "2    Africa  Dem. Rep. of the Congo  2010                 11.0      81.0\n",
       "7    Europe                 Denmark  2005               5293.0    9178.0\n",
       "8    Europe                 Denmark  2010               5704.0    8744.0\n",
       "9    Europe                 Denmark  2017               8508.0   12426.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f07e7dd0-4b69-41f8-b87e-988749cebcac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split \u001b[38;5;28;01mas\u001b[39;00m tts\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#use random state 201\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m tts(\u001b[43mx\u001b[49m, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m201\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "#use random state 201\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(x, y, test_size=0.2, shuffle=True, random_state=201)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf722de4-bde7-451d-b04e-d9cb55ffb96e",
   "metadata": {},
   "source": [
    "#### K-fold validation\n",
    "\n",
    "The idea of K-fold validation is to make each batch of data as the testing data so that there are no discrepancies and bias between what we're choosing for training data and testing data.\n",
    "\n",
    "You will make $k$ models during this process.\n",
    "\n",
    "1. Split data into $k$ equally sized groups, called **folds**\n",
    "2. Use the first fold as testing data, and then merge the rest of the folds into a group as the training data.\n",
    "3. Move on to make the second fold as the testing data, and then merge the rest of the folds into a group as the training data.\n",
    "4. Continue this process until you cover all the folds.\n",
    "\n",
    "- Each fold will be in the training data $k-1$ times\n",
    "- Each fold will be the testing data 1 time.\n",
    "\n",
    "**Theory of k**\n",
    "\n",
    "The value of $k$ has a bias-variance tradeoff. \n",
    "\n",
    "- As the number of folds $k$ increases, You do better on training data and do worse on testing data (testing data is a smaller portion of data) and thus **variance increases**\n",
    "- As the number of folds $k$ decreases, You do worse on training data and do better on testing data (testing data is a bigger portion of data, and you're training on less of data) and thus **bias increases**\n",
    "\n",
    "**Using kfold**\n",
    "\n",
    "1. Import `kfold`\n",
    "\n",
    "   ```python\n",
    "   from sklearn.model_selection import KFold\n",
    "   ```\n",
    "\n",
    "2. Create a kfold instance from the `KFold` class\n",
    "\n",
    "   ```python\n",
    "   kf = KFold(n_splits = 10, random_state=146, shuffle=True)\n",
    "   ```\n",
    "\n",
    "\n",
    "3. Use the `kf.split(data)` method to create kfold splits on your data, which should be a 2D array. This method returns a generator, so you should iterate through it\n",
    "\n",
    "    ```python\n",
    "    for idxTrain, idxTest in kf.split(x):\n",
    "        Xtrain = x[idxTrain]\n",
    "        Xtest = x[idxTest]\n",
    "        ytrain = y[idxTrain]\n",
    "        ytest = y[idxTest]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae8a9f5-ec1a-4a38-a23d-ef636d36eeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_data(size=20):\n",
    "    np.random.seed(210)\n",
    "    x= np.random.normal(size=(size,1))\n",
    "    noise_strength = 0.2\n",
    "    noise = np.random.normal(scale=noise_strength, size=(size,1))*100\n",
    "    y = 100 + 200*x + noise\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fef9665-c433-47de-af69-6a2bcaec934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "lr = LR()\n",
    "\n",
    "kf = KFold(n_splits = 10, random_state=146, shuffle=True)\n",
    "scores = []\n",
    "\n",
    "for idxTrain, idxTest in kf.split(x):\n",
    "    Xtrain = x[idxTrain]\n",
    "    Xtest = x[idxTest]\n",
    "    ytrain = y[idxTrain]\n",
    "    ytest = y[idxTest]\n",
    "\n",
    "    # build the model\n",
    "    lr.fit(Xtrain, ytrain)\n",
    "    test_score = lr.score(Xtest, ytest)\n",
    "    train_score = lr.score(Xtrain, ytrain)\n",
    "    print(f\"train score: {train_score}\\t test score: {test_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309b7aa3-a0af-48b9-93cb-7885f1557fab",
   "metadata": {},
   "source": [
    "This is a convenience function to do kfold with any kind of scikit learn model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb46b8d9-86f2-4132-848a-6e51ee5c2684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def do_Kfold(model,X,y,k,scaler = None, random_state = 146):\n",
    "    \n",
    "    kf = KFold(n_splits=k, random_state = random_state, shuffle=True)\n",
    "\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "\n",
    "    for idxTrain, idxTest in kf.split(X):\n",
    "        Xtrain = X[idxTrain, :]\n",
    "        Xtest = X[idxTest, :]\n",
    "        ytrain = y[idxTrain]\n",
    "        ytest = y[idxTest]\n",
    "        if scaler != None:\n",
    "            Xtrain = scaler.fit_transform(Xtrain)\n",
    "            Xtest = scaler.transform(Xtest)\n",
    "\n",
    "        model.fit(Xtrain,ytrain)\n",
    "\n",
    "        train_scores.append(model.score(Xtrain,ytrain))\n",
    "        test_scores.append(model.score(Xtest,ytest))\n",
    "        \n",
    "    return train_scores, test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c2cbb6-4f23-467d-9e69-32a10826e5bd",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "\n",
    "Regularization punishes parameters to mitigate overfitting. By adding the parameters to the cost function, gradient descent aims to decrease the values of those parameters to make the hypothesis simpler.\n",
    "\n",
    "There are three types of regularization: \n",
    "\n",
    "- L1 regression: regularization using the $L_1$ norm\n",
    "- L2 regression: regularization using the $L_2$ norm\n",
    "- elastic regression: regularization combining both L1 and L2 regualrization\n",
    "\n",
    "**$L_1$ regularization**\n",
    "\n",
    "$L_1$ regularization, also called **lasso regression**, sums up the absolute value (L1 norm) of all the parameters and adds that to the cost function \n",
    "\n",
    "$$J = \\sum_{i=1}^N (y_i - \\hat{y}_i)^2 + \\alpha \\sum_{j=1}^n |\\beta_i|$$\n",
    "\n",
    "**$L_2$ regularization**\n",
    "\n",
    "$L_2$ regularization, also called **lasso regression**, sums up the squares (L2 norm) of all the parameters and adds that to the cost function \n",
    "\n",
    "$$J = \\sum_{i=1}^N (y_i - \\hat{y}_i)^2 + \\alpha \\sum_{j=1}^n \\beta_i^{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7148acc9-ef1f-4cb5-a4b4-ac8a6d795ed9",
   "metadata": {},
   "source": [
    "#### Ridge Regresssion \n",
    "\n",
    "Here is the cost function for ridge regression, which serves to add the beta coefficients to the cost function so that we can penalize them. \n",
    "\n",
    "- $N$ : the number of training rows you have\n",
    "- $n$ : the number of features/parameters\n",
    "- $\\alpha$ : the regularization hyperparameter\n",
    "\n",
    "$$J = \\sum_{i=1}^N (y_i - \\hat{y}_i)^2 + \\alpha \\sum_{j=1}^n \\beta_i^{2}$$\n",
    "\n",
    "**Effect of regularization parameter**\n",
    "\n",
    "- As $\\alpha$ increases, the hypothesis becomes extremely more simple \n",
    "- As $\\alpha$ decreases, the hypothesis becomes slightly more simple\n",
    "\n",
    "A high value of $\\alpha$ penalizes the parameters a lot so that they are essentially 0, and the less that value, the less you are penalizing those parameters and thus the parameters only slightly decrease. \n",
    "\n",
    "**Scaling**\n",
    "\n",
    "You must always scale data with ridge regression so that they can all be penalized appropriately.\n",
    "\n",
    "1. Scale training features\n",
    "2. Scale testing features with the same scaler parameters as you did for the training data.\n",
    "\n",
    "```python\n",
    "ss = SS()\n",
    "ss.fit(Xtrain)\n",
    "\n",
    "# scale both training and testing data with scaler (based on training specs)\n",
    "scaled_Xtrain = ss.transform(Xtrain)\n",
    "scaled_Xtest = ss.transform(Xtest)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a575d13a-794b-49c6-bb94-cf9f909e8cf5",
   "metadata": {},
   "source": [
    "##### Hyperparameter optimization\n",
    "\n",
    "Hyperparameter optimiziation is where we try to choose the best value for a hyperparameter that makes our model perform the best.\n",
    "\n",
    "We always do hyperparameter optimization before training a model. Here are the steps we follow: \n",
    "\n",
    "1. Create a range for the $\\alpha$ values, like an array of hyperparameter values to test\n",
    "2. Loop through that range, and for each $\\alpha$ parameter, perform ridge regression with the regularization hyperparameter set to $\\alpha$, and add that score to a list of model scores.\n",
    "3. Graph the alpha values against the list of model scores. THe optimal alpha lies at the peak of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93a4fd37-4853-47e6-9153-e99dcca1470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "\n",
    "def getOptimalAlpha() -> int :\n",
    "    # 1. setup kfold and scaler \n",
    "    k = 10\n",
    "    ss = SS()\n",
    "\n",
    "    # 2. create array of possible alpha values\n",
    "    a_range = np.linspace(10,20,100)\n",
    "    \n",
    "    avg_tr_score=[]\n",
    "    avg_te_score=[]\n",
    "    \n",
    "    for a in a_range:\n",
    "        # 3. run model\n",
    "        rid_reg = Ridge(alpha=a)\n",
    "        train_scores, test_scores = do_Kfold(rid_reg, X, y, k, ss)\n",
    "\n",
    "        # 4. collect statistics\n",
    "        avg_tr_score.append(np.mean(train_scores))\n",
    "        avg_te_score.append(np.mean(test_scores))\n",
    "\n",
    "        # 5. return alpha that gave highest test score\n",
    "        idx_max = np.argmax(avg_te_score)\n",
    "        return a_range[idx_max]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90158bc0-fd58-4a59-abbd-e22ca3028b81",
   "metadata": {},
   "source": [
    "##### Performing ridge regression\n",
    "\n",
    "1. Install the appropriate scaling and L2 regularization\n",
    "\n",
    "    ```python\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.preprocessing import StandardScaler as SS\n",
    "    ```\n",
    "\n",
    "2. Create a ridge regression model by instantiating the `Ridge()` class, and passing in a value for $\\alpha$ through the `alpha=` kwarg\n",
    "\n",
    "    ```python\n",
    "    ridge_regression = Ridge(alpha=1)\n",
    "    ```\n",
    "\n",
    "Then this ridge ression model works the exact same as the linear model from scikit learn, where you can use the `fit()`, `predict()`, and `score()` methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624c3964-5d7e-4716-ab70-26ab321ad918",
   "metadata": {},
   "source": [
    "#### Lasso Regression\n",
    "\n",
    "Here is the cost function for lasso regression, which serves to add the beta coefficients to the cost function so that we can penalize them. \n",
    "\n",
    "- $N$ : the number of training rows you have\n",
    "- $n$ : the number of features/parameters\n",
    "- $\\alpha$ : the regularization hyperparameter\n",
    "\n",
    "$$J = \\sum_{i=1}^N (y_i - \\hat{y}_i)^2 + \\alpha \\sum_{j=1}^n |\\beta_i|$$\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"max-width:30rem\">\n",
    "The difference between lasso regression and ridge regression is that lasso regression can essentially delete features by reducing them to 0, while ridge regression can't.\n",
    "</div>\n",
    "\n",
    "**Using lasso regression**\n",
    "\n",
    "\n",
    "1. Install the appropriate scaling and L1 regularization\n",
    "\n",
    "    ```python\n",
    "    from sklearn.linear_model import Lasso\n",
    "    from sklearn.preprocessing import StandardScaler as SS\n",
    "    ```\n",
    "\n",
    "2. Create a lasso regression model by instantiating the `Lasso()` class, and passing in a value for $\\alpha$ through the `alpha=` kwarg\n",
    "\n",
    "    ```python\n",
    "    lasso_regression = Lasso(alpha=1)\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba83268-742a-44a4-a87d-fdd7b12744e9",
   "metadata": {},
   "source": [
    "## PCA and dimensionality reduction\n",
    "\n",
    "https://www.youtube.com/watch?v=FgakZw6K1QQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285ef298-ace4-470e-a5e8-e540cd493a42",
   "metadata": {},
   "source": [
    "### Dimensionality reduction\n",
    "\n",
    "Dimensionsality reduction reduces features, eliminating them to reduce model complexity.\n",
    "\n",
    "- **curse of dimensionality** : higher dimensionality usually leads to overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edec2aa6-4f26-430d-a51f-01ca3a7d3532",
   "metadata": {},
   "source": [
    "### PCA introduction\n",
    "\n",
    "When plotting all features against each other, we then project all the points onto a single axis for every axis. We find the axis that preserves the most variation in the data. \n",
    "\n",
    "The first principal component will be the feature/variable that has the most variance, followed by others in decreasing variance. \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    PCA creates new variables that are linear combinations of the original variables. \n",
    "</div>\n",
    "\n",
    "Because they are linear combinations, they can reduce the coefficients for a principal component / feature to 0, essentially eliminating that feature. \n",
    "\n",
    "**Theory**\n",
    "\n",
    "Plot all points on a graph. Find the line of best fit (done by first initializing a random line, and then trying to maximize the distance of the projected points onto the line from the origin), which gives you the first principal component. \n",
    "\n",
    "Principal components are just lines, so they are linear combinations of the features. Here is how you find the rest of the principal components: \n",
    "\n",
    "- **PC2** : orthogonal to PC1 and goes through origin\n",
    "- **PC3** : orthogonal to both PC1 and PC2 and goes through origin. \n",
    "\n",
    "**Properties of PCA**\n",
    "\n",
    "\n",
    "- PCA does not cluster data. It finds patterns `in data\n",
    "- PCA requires scaling since it depends on distance metrics. \n",
    "\n",
    "**Code**\n",
    "\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pca_data = pca.fit_transform(X)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dc4f01-dbda-4131-a2c3-d4a88974300c",
   "metadata": {},
   "source": [
    "### TSNE\n",
    "\n",
    "TSNE is a type of non-linear dimensionality reduction, also called manifold learning. \n",
    "\n",
    "Here are the differences between PCA and TSNE: \n",
    "\n",
    "- PCA is deterministic while TSNE is stochastic (random) and iterative (but you can set the random state to get the same output).\n",
    "- PCA is linear while TSNE is non-linear\n",
    "- PCA focuses on global relationships while TSNE focuses on *local* relationships within data\n",
    "- TSNE is better at finding distinct groups than PCA.\n",
    "\n",
    "TSNE creates a gaussian distribution of the data\n",
    "\n",
    "**Perplexity**\n",
    "\n",
    "Perplexity is the main hyperparameter for TSNE, and refers to the number of neighbors each data point should try to preserve. \n",
    "\n",
    "- If the perplexity is too high, the points will roughly form a circle.\n",
    "- If the perplexity is too small, you will have a bunch of tiny clusters of points\n",
    "\n",
    "**SKLearn**\n",
    "\n",
    "```python\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE()\n",
    "tsne_data = tsne.fit_transform(X)\n",
    "```\n",
    "\n",
    "Here are the kwargs you can pass in to the `TSNE()` constructor: \n",
    "\n",
    "- `random_state=` : to set random state number for tsne\n",
    "- `perplexity=` : sets the amount of perplexity for the tsne model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25eed64-54c7-4849-bdbd-ec47db64c448",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "**Classification metrics**\n",
    "\n",
    "If data is unbalanced, we need recall and precision to truly evaluate a model's performance. \n",
    "\n",
    "- **Accuracy**: True positives / (total classified)\n",
    "- **recall** : $\\frac{TP}{TP + FN}$. Recall asks the question, \"what percentage of the positive cases does the model correctly predict as positive?\"\r\n",
    "- **precision** $\\frac{TP}{TP + FP}$. Precision asks the question, \"when we predict a case as positive, how often is it correct?\"\r\n",
    "- **F1 score** : the harmonic mean of precision and recall, used to join both into a single universal scoring metric. F1 score will be 0 if either precision or recall equals 0, so this metric tries to strike a good balance between precision and recal\n",
    "\n",
    "**Precision and recall problems**\n",
    "\n",
    "When doing precision and recall matrix problems, remember these two facts: \n",
    "\n",
    "- Precision is vertical\n",
    "- Recall is horizontal\n",
    "\n",
    "Recall asks this question: For all values that actually belongs to class A, what was the percentage we correctly predicted as class A?\n",
    "\n",
    "Precision asks this question: When we predicted something as belonging to class A, what was the percentage that actually belonged to class A?l."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c34ff5-12ab-4ef7-9e40-e87c043a1555",
   "metadata": {},
   "source": [
    "### Important methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a4a52f0-a524-4376-bb23-bcce31802a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_Kfold(model,X,y,k,scaler = None, random_state = 146):\n",
    "    from sklearn.model_selection import KFold\n",
    "    \n",
    "    kf = KFold(n_splits=k, random_state = random_state, shuffle=True)\n",
    "\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "\n",
    "    for idxTrain, idxTest in kf.split(X):\n",
    "        Xtrain = X[idxTrain, :]\n",
    "        Xtest = X[idxTest, :]\n",
    "        ytrain = y[idxTrain]\n",
    "        ytest = y[idxTest]\n",
    "        if scaler != None:\n",
    "            Xtrain = scaler.fit_transform(Xtrain)\n",
    "            Xtest = scaler.transform(Xtest)\n",
    "\n",
    "        model.fit(Xtrain,ytrain)\n",
    "\n",
    "        train_scores.append(model.score(Xtrain,ytrain))\n",
    "        test_scores.append(model.score(Xtest,ytest))\n",
    "        \n",
    "    return train_scores, test_scores\n",
    "\n",
    "def compare_classes(actual, predicted, names=None):\n",
    "    '''Function returns a confusion matrix, and overall accuracy given:\n",
    "            Input:  actual - a list of actual classifications\n",
    "                    predicted - a list of predicted classifications\n",
    "                    names (optional) - a list of class names\n",
    "    '''\n",
    "    accuracy = sum(actual==predicted)/actual.shape[0]\n",
    "    \n",
    "    classes = pd.DataFrame(columns = ['Actual', 'Predicted'])\n",
    "    classes['Actual'] = actual\n",
    "    classes['Predicted'] = predicted\n",
    "\n",
    "    conf_mat = pd.crosstab(classes['Actual'], classes['Predicted'])\n",
    "    \n",
    "    if type(names) != type(None):\n",
    "        conf_mat.index = names\n",
    "        conf_mat.index.name = 'Actual'\n",
    "        conf_mat.columns = names\n",
    "        conf_mat.columns.name = 'Predicted'\n",
    "    \n",
    "    print('Accuracy = ' + format(accuracy, '.2f'))\n",
    "    return conf_mat, accuracy\n",
    "\n",
    "def plot_groups(points, groups, colors, \n",
    "               ec='black', ax='None',s=30, alpha=0.5,\n",
    "               figsize=(6,6)):\n",
    "    '''Creates a scatter plot, given:\n",
    "            Input:  points (array) X, features\n",
    "                    groups (an integer label for each point) y, target\n",
    "                    colors (one rgb tuple for each group)\n",
    "                    ec (edgecolor for markers, default is black)\n",
    "                    ax (optional handle to an existing axes object to add the new plot on top of)\n",
    "            Output: handles to the figure (fig) and axes (ax) objects\n",
    "    '''\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    # Create a new plot, unless something was passed for 'ax'\n",
    "    if ax == 'None':\n",
    "        fig,ax = plt.subplots(figsize=figsize)\n",
    "    else:\n",
    "        fig = plt.gcf()\n",
    "    \n",
    "    for i,lbl in enumerate(np.unique(groups)):\n",
    "        idx = (groups==lbl)\n",
    "        ax.scatter(points[idx,0], points[idx,1],color=colors[i],\n",
    "                    ec=ec,alpha=alpha,label = lbl,s=s)\n",
    "    ax.set_xlabel('$x_1$')\n",
    "    ax.set_ylabel('$x_2$')\n",
    "    ax.legend(bbox_to_anchor=[1, 0.5], loc='center left')\n",
    "    return fig, ax\n",
    "\n",
    "def get_colors(N, map_name='rainbow'):\n",
    "    '''Returns a list of N colors from a matplotlib colormap\n",
    "            Input: N = number of colors, and map_name = name of a matplotlib colormap\n",
    "    \n",
    "            For a list of available colormaps: \n",
    "                https://matplotlib.org/3.1.1/gallery/color/colormap_reference.html\n",
    "    '''\n",
    "    import matplotlib\n",
    "    cmap = matplotlib.cm.get_cmap(name=map_name)\n",
    "    n = np.linspace(0,1,N)\n",
    "    colors = cmap(n)\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae62948-b010-4093-b95b-e03b30c7ecb4",
   "metadata": {},
   "source": [
    "### K nearest neighbors\n",
    "\n",
    "In the k nearest neighbors algorithm, we choose a number $k$, and in the corrdinate space, we consider a data point's distance to the $k$ nearest points to that data point. \n",
    "\n",
    "We assign that data point to a class if out of those k points and each of those points belong to a class, the majority of the k points are part of one class. \n",
    "\n",
    "**Train vs test**\n",
    "\n",
    "For k nearest numbers, we want to keep train sets large and test sets small. \n",
    "\n",
    "**Scaling**\n",
    "\n",
    "Scaling is necessary for K nearest neighbors. \n",
    "\n",
    "**Distance metric**\n",
    "\n",
    "The default distance metric for KNN is `uniform`, meaning every point is weighted equally. You can change this with the `weights=` kwarg when instantiating the `KNN()` object. \n",
    "\n",
    "Distance metrics come into play when deciding how to tally up a positive prediction or a negative prediction from the k nearest points.\n",
    "\n",
    "- **`'uniform'`** : Each point is weighted equally, no matter how far away it is from the data point.\n",
    "- **`'distance'`** : A point is weighted higher if it's closer to the data point being considered. Each point in the K nearest points to a data point is given a *weight*, which is the inverse of the distance from that point to the data point, 1 / distance. \n",
    "\n",
    "**Code**\n",
    "\n",
    "1. Import\n",
    "\n",
    "   ```python\n",
    "   from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "   from sklearn.preprocessing import StandardScaler as SS\n",
    "   ```\n",
    "\n",
    "2. Create model\n",
    "\n",
    "   ```python\n",
    "   knn = KNN(n_neighbors=5)\n",
    "   ```\n",
    "\n",
    "3. Fit model\n",
    "\n",
    "   ```python\n",
    "   knn.fit(X, y)\n",
    "   ```\n",
    "\n",
    "**KNN() kwargs**\n",
    "\n",
    "- `n_neighbors=` : the number of neighbors to set for the algorithm.\n",
    "- `weights=` : changes the distance metric. Default is `'uniform'`, where all points are weighted equally \n",
    "\n",
    "**Methods**\n",
    "\n",
    "- `knn.predict_proba(X)` : returns a soft classification for the features, giving probabilities for each class\n",
    "- `knn.predict(X)` : returns hard classification and classifies the observations to labels.\n",
    "- `knn.score(X, y)`: returns the accuracy of the model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a97afe64-979c-43fc-b8d8-a5e95b439b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "from sklearn.datasets import make_moons, make_blobs as mb, load_breast_cancer as lbc, load_iris as li\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9957f7-cbec-4d75-90ed-9982e2a39c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_kfold(X, y, k):    \n",
    "    neighbor_range = np.array(range(2,k))\n",
    "    train=[]\n",
    "    test=[]\n",
    "    \n",
    "    # run through k nearest neighbord k times, doing k fold\n",
    "    for n_neighbors in neighbor_range:\n",
    "        knn = KNN(n_neighbors=n_neighbors)\n",
    "        tr, te = do_Kfold(knn, X, y, k, scaler=SS())\n",
    "        train.append(np.mean(tr))\n",
    "        test.append(np.mean(te))\n",
    "\n",
    "    # plot error against k\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot(neighbor_range, train, ':xk', label='Training')\n",
    "    plt.plot(neighbor_range, test, ':xr', label='Testing')\n",
    "    plt.ylabel('Mean accuracy', fontsize=14)\n",
    "    plt.xlabel('$k$',fontsize=14)\n",
    "    plt.xticks(neighbor_range)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64721eb-a424-4bff-a462-eba2c2077508",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "Logistic regression is used for classification tasks, but like regression, it also outputs a single number. \n",
    "\n",
    "The hypothesis uses the sigmoid function to make sure all probability outputs are between 0 and 1. \n",
    "\n",
    "$$h_{\\beta}(\\vec x) = \\sigma (\\vec \\beta \\cdot \\vec x) = \\frac{1}{1 + e^{-\\vec \\beta \\cdot \\vec x}}$$\n",
    "\n",
    "The single number returned from logisitic regression is called the **log odds**, which just follows this formula: \n",
    "\n",
    "$$\\log{\\frac{P(\\mathrm{class \\ 1})}{P(\\mathrm{class \\ 0})}}$$\n",
    "\n",
    "You find the probability of being in class 1, divide that by the probability of being in class 0, and then take the logarithm of that quotient to get the log odds.\n",
    "\n",
    "**Hyperparameter c**\n",
    "\n",
    "Logistic regression uses L2 regularization, the hyperparameter $c$ controls that behavior, acting as the penalty for regularization. \n",
    "\n",
    "- smaller $c$, more regularization\n",
    "\n",
    "**Multi-class regression**\n",
    "\n",
    "There are two methods for multiclass logistic regression. \n",
    "\n",
    "- **One vs rest**: We do repeated loops of treating one class as the positive class, and lumping all other classes together as the negative class.\n",
    "- **Multinomial**: We do a softmax classification where all the classes have their own probability, and all together they sum to 1. This is the default for scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3268c3ad-3350-450c-86dd-c0553cdbeef3",
   "metadata": {},
   "source": [
    "#### Logistic regression coding\n",
    "\n",
    "1. Import like so\n",
    "\n",
    "   ```python\n",
    "   from sklearn.linear_model import LogisticRegression\n",
    "   ```\n",
    "\n",
    "2. Create the model\n",
    "\n",
    "   ```python\n",
    "   log_reg = LogisticRegression()\n",
    "   ```\n",
    "\n",
    "\n",
    "**Model hyperparameters**\n",
    "\n",
    "Here are the kwargs you can pass in to the model to tune the hyperparameters: \n",
    "\n",
    "- `C` : the number amount of regularization. A smaller amount means more regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71280715-f89d-4acf-b698-470f71b2881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "log_reg = LR()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a92bf21-604c-4cef-b433-3554296e8087",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "**Theory**\n",
    "\n",
    "- root node has a depth of **0**\n",
    "\n",
    "**Gini impurity**\n",
    "\n",
    "The intuition behind the gini impurity coefficient is that it's the probability of misclassifying a data point within a dataset. \n",
    "\n",
    "- If all data points in a subset are of the same class, the probability of misclassifying that data point is 0 and thus the Gini impurity coefficient is 0.\n",
    "\n",
    "A decision tree tries to minimize the Gini impurity at every step. It keeps splitting at every node until a node reaches an impurity value = 0 or doesn't have enough observations falling into that node to split on, which makes it a **leaf node**.\n",
    "\n",
    "**Hyperparameters**\n",
    "\n",
    "- `min_samples_split` : how many observations in the parent node it needs in order to split (and have child nodes). This prevents overfitting by preventing too many branches until you reach completely pure nodes.\n",
    "- `min_samples_leaf` : the minimum amount of observations that each leaf should have. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61425a43-f57e-4754-a604-68859ed2b155",
   "metadata": {},
   "source": [
    "#### Decision tree coding\n",
    "\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "\n",
    "dtc = DTC(random_state=201)\n",
    "dtc.fit(Xtrain, ytrain)\n",
    "```\n",
    "\n",
    "**Decision tree kwargs/hyperparameters**\n",
    "\n",
    " - `random_state=` : sets the random state for the decision tree\n",
    "\n",
    "**Decision tree methods**\n",
    "\n",
    "- `dtc.score(X, y)` : returns the accuracy score\n",
    "- `dtc.get_depth()` : returns the depth of the tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd322d68-2afe-49f6-b20a-2e7074c46c45",
   "metadata": {},
   "source": [
    "### Random forests\n",
    "\n",
    "**Ensemble models**\n",
    "\n",
    "Ensemble models are composed of multiple individual models, and they can different combinations of models. You then combine the results from all the models in some way to get one final result. \n",
    "\n",
    "An example of an ensemble model is having one model as K nearest neighbors with one model as Logistic Regression, etc. \n",
    "\n",
    "**Random forests**\n",
    "\n",
    "Random forests are ensemble models made up of only multiple decision trees. Here are the basic ideas: \n",
    "\n",
    "- All trees use the exact same hyperparameters\n",
    "- Random forests use bootstrapping (random sampling with replacement) to change the training data passed to each tree. We do this instead of just having smaller unique data for each tree because more training data is good. \n",
    "\n",
    "**Scikit-learn**\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "rfc = RFC(random_state=201)\n",
    "rfc.fit(Xtrain, ytrain)\n",
    "```\n",
    "\n",
    "**Hyperparameters**\n",
    "\n",
    "- `min_samples_split` : a higher value for this hyperparameter constrains the tree more\n",
    "- `min_samples_leaf` : a higher value for this hyperparameter constrains the tree more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7689697c-e82c-4ece-b513-dea8f4ae2b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_optimal_hyperparameter(train, test, params):\n",
    "    max_idx = np.argmax(test)\n",
    "    print(\"optimal hyperparameter =\", params[max_idx])\n",
    "    print(\"training score at optimal hyperaparameter:\", train[max_idx])\n",
    "    print(\"testing score at optimal hyperaparameter:\", test[max_idx])\n",
    "    return params[max_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8cfcc9c-9c3c-4622-bca9-43b15d0915ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.array(\n",
    "    [[0.36, 0.49, 0.15],\n",
    "    [0.44, 0.41, 0.15],\n",
    "    [0.39, 0.31, 0.30]]\n",
    ")\n",
    "\n",
    "def hard_classification(probs):\n",
    "    pass\n",
    "\n",
    "def soft_classification(probs): \n",
    "    sums = []\n",
    "    for outcome in range(probs.shape[1]): \n",
    "        sums.append(np.sum(probs[:, outcome]))\n",
    "    averages = np.array([x / probs.shape[1] for x in sums])\n",
    "    print(f\"predicted class: {np.argmax(averages)+1}\")\n",
    "    return averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64442e3e-9390-4df1-9f4e-6e386ba9f48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.39666667, 0.40333333, 0.2       ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_classification(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea468b2-0293-4a08-b6b4-9fd30f184e28",
   "metadata": {},
   "source": [
    "#### Cardinality\n",
    "\n",
    "**Cardinality** of a feature refers to how many unique values that feature has. \n",
    "\n",
    "For features with a high count or potential of unique values, you need more data to have robust training on them.\n",
    "\n",
    "High cardinality features can increase the complexity of models, particularly those based on tree algorithms. Decision trees, for example, may struggle to effectively split on high cardinality features, leading to inefficient use of computational resources and potentially overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea028272-c08b-4303-b2b9-0c6d24e0f5b5",
   "metadata": {},
   "source": [
    "### Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab94009-8f48-41bf-ae65-863b4075e504",
   "metadata": {},
   "source": [
    "#### Hard classifications vs Soft classification for random forests\n",
    "\n",
    "For random forests, we have the choice between hard classification and soft classification for random forest ensemble models. \n",
    "\n",
    "**Soft classification**\n",
    "\n",
    "Add up the individual probabilities for each class, and then average that to get an average probability for each class. \n",
    "\n",
    "<div class=\"alert alert-warning\">Scikit-learn uses soft classification</div>\n",
    "\n",
    "**Hard classification**\n",
    "\n",
    "For each outcome, adds a vote for the class who had the highest probability. THe class with the most total votes wins it all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1d49c6a-764f-453f-a7c7-610b99be532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.array(\n",
    "    [[0.36, 0.49, 0.15],\n",
    "    [0.44, 0.41, 0.15],\n",
    "    [0.39, 0.31, 0.30]]\n",
    ")\n",
    "\n",
    "def hard_classification(probs):\n",
    "    num_classes = probs.shape[1]\n",
    "    votes = [0 for i in range(num_classes)]\n",
    "    decisions = np.argmax(probs, axis=1)\n",
    "\n",
    "    for class_ in decisions: \n",
    "        votes[class_] += 1\n",
    "\n",
    "    print(f\"predicted class: {np.argmax(votes)+1}\")\n",
    "    return np.array(votes)\n",
    "\n",
    "def soft_classification(probs): \n",
    "    sums = []\n",
    "    for outcome in range(probs.shape[1]): \n",
    "        sums.append(np.sum(probs[:, outcome]))\n",
    "    averages = np.array([x / probs.shape[1] for x in sums])\n",
    "    print(f\"predicted class: {np.argmax(averages)+1}\")\n",
    "    return averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d8cc033-e444-4daf-9634-4de50f2087fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.39666667, 0.40333333, 0.2       ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_classification(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "811b097a-c4b2-4aa1-95b9-d2a20ddde3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_classification(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a283e64f-9ed1-44b2-ac83-3d22591223d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Leave one-out validation\n",
    "\n",
    "Leave one out validation is where you train on every single observation except for one, which is your test set. This is extremely useful when paired with K nearest neighbors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b8d7a3-b2f3-4611-849b-2148159c0e57",
   "metadata": {},
   "source": [
    "#### Grid search\n",
    "\n",
    "Here are the essential components to grid search: \n",
    "\n",
    "- **estimator** : the model to run grid search on\n",
    "- **param grid** : the dictionary of hyperparameters to try and optimize\n",
    "- **cv** : the KFold validation and number of folds to use\n",
    "- **scoring**: how the Grid model shoudl evaluate performance to select the best estimator.\n",
    "\n",
    "**Grid search kwargs**\n",
    "\n",
    "- `cv=` : the custom cross validation to use, like a custom KFold instance. By default it's 5 folds KFold validation.\n",
    "- `scoring=` : string, how the Grid model should evaluate performance to select the best estimator.\n",
    "  - `\"accuracy\"` : uses accuracy as the score. Useful for classification\n",
    "  - `\"neg_mean_squared_error\"` : uses negative mean squared error as score. Useful for regression\n",
    "  - `\"recall\"`: uses recall as the score\n",
    "\n",
    "**Grid search model attributes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af5d3727-8835-4d0a-a5b8-58ecfa8a1f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "# 1. create parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators' : [64, 100, 128],\n",
    "    'max_depth' : [2,3,4,5],\n",
    "    'min_samples_split' : [2,3,4,5]\n",
    "}\n",
    "\n",
    "# 2. create custom cv validation\n",
    "cv = KFold(n_splits=10, random_state=146, shuffle=True)\n",
    "\n",
    "# 3. create estimator\n",
    "estimator = RFC()\n",
    "\n",
    "# 4. create grid search\n",
    "grid = GridSearchCV(estimator, param_grid, cv=cv, scoring='accuracy')\n",
    "\n",
    "# 5. train grid\n",
    "grid.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f09679-6e13-4e85-8c49-6f6fc1d63d00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
